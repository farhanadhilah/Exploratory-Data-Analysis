{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farhanadhilah/Exploratory-Data-Analysis/blob/main/Crawling%20Pertamax%20Tweets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zT6RQcu87WvZ"
      },
      "source": [
        "# **Social Media Analytics (Twitter)**\n",
        "\n",
        "\n",
        "Nadhilah Farhana (2106779516)\n"
      ],
      "id": "zT6RQcu87WvZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Data Crawling**"
      ],
      "metadata": {
        "id": "eWEE-KxP-IXd"
      },
      "id": "eWEE-KxP-IXd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "24430ad1",
        "outputId": "394763c1-8413-4561-d63a-7e24708b2ab8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-19 14:27:35--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/taudataDDGsna.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 8030 (7.8K) [text/plain]\n",
            "Saving to: ‘taudataDDGsna.py.1’\n",
            "\n",
            "\rtaudataDDGsna.py.1    0%[                    ]       0  --.-KB/s               \rtaudataDDGsna.py.1  100%[===================>]   7.84K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-19 14:27:35 (68.9 MB/s) - ‘taudataDDGsna.py.1’ saved [8030/8030]\n",
            "\n",
            "mkdir: cannot create directory ‘data’: File exists\n",
            "--2023-04-19 14:27:35--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/contoh.pdf\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 221233 (216K) [application/octet-stream]\n",
            "Saving to: ‘data/contoh.pdf.1’\n",
            "\n",
            "contoh.pdf.1        100%[===================>] 216.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-19 14:27:35 (12.6 MB/s) - ‘data/contoh.pdf.1’ saved [221233/221233]\n",
            "\n",
            "--2023-04-19 14:27:35--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/slang.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 29041 (28K) [text/plain]\n",
            "Saving to: ‘data/slang.txt.1’\n",
            "\n",
            "slang.txt.1         100%[===================>]  28.36K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2023-04-19 14:27:36 (17.8 MB/s) - ‘data/slang.txt.1’ saved [29041/29041]\n",
            "\n",
            "--2023-04-19 14:27:36--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_id.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 6446 (6.3K) [text/plain]\n",
            "Saving to: ‘data/stopwords_id.txt.1’\n",
            "\n",
            "stopwords_id.txt.1  100%[===================>]   6.29K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-19 14:27:36 (80.3 MB/s) - ‘data/stopwords_id.txt.1’ saved [6446/6446]\n",
            "\n",
            "--2023-04-19 14:27:36--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_en.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 15140 (15K) [text/plain]\n",
            "Saving to: ‘data/stopwords_en.txt.1’\n",
            "\n",
            "stopwords_en.txt.1  100%[===================>]  14.79K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-04-19 14:27:36 (44.1 MB/s) - ‘data/stopwords_en.txt.1’ saved [15140/15140]\n",
            "\n",
            "--2023-04-19 14:27:36--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/kata_dasar.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 348507 (340K) [text/plain]\n",
            "Saving to: ‘data/kata_dasar.txt.1’\n",
            "\n",
            "kata_dasar.txt.1    100%[===================>] 340.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-19 14:27:36 (13.7 MB/s) - ‘data/kata_dasar.txt.1’ saved [348507/348507]\n",
            "\n",
            "--2023-04-19 14:27:36--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-ind-def.tab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 868322 (848K) [text/plain]\n",
            "Saving to: ‘data/wn-ind-def.tab.1’\n",
            "\n",
            "wn-ind-def.tab.1    100%[===================>] 847.97K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2023-04-19 14:27:37 (23.2 MB/s) - ‘data/wn-ind-def.tab.1’ saved [868322/868322]\n",
            "\n",
            "--2023-04-19 14:27:37--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-msa-all.tab\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17003012 (16M) [text/plain]\n",
            "Saving to: ‘data/wn-msa-all.tab.1’\n",
            "\n",
            "wn-msa-all.tab.1    100%[===================>]  16.21M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2023-04-19 14:27:37 (157 MB/s) - ‘data/wn-msa-all.tab.1’ saved [17003012/17003012]\n",
            "\n",
            "--2023-04-19 14:27:37--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/ind_SA.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 918025 (897K) [text/plain]\n",
            "Saving to: ‘data/ind_SA.csv.1’\n",
            "\n",
            "ind_SA.csv.1        100%[===================>] 896.51K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-04-19 14:27:37 (31.4 MB/s) - ‘data/ind_SA.csv.1’ saved [918025/918025]\n",
            "\n",
            "--2023-04-19 14:27:38--  https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/all_indo_man_tag_corpus_model.crf.tagger\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1722780 (1.6M) [application/octet-stream]\n",
            "Saving to: ‘data/all_indo_man_tag_corpus_model.crf.tagger.1’\n",
            "\n",
            "all_indo_man_tag_co 100%[===================>]   1.64M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2023-04-19 14:27:38 (50.4 MB/s) - ‘data/all_indo_man_tag_corpus_model.crf.tagger.1’ saved [1722780/1722780]\n",
            "\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.9/dist-packages (3.5.1)\n",
            "Collecting spacy\n",
            "  Using cached spacy-3.5.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "Collecting python-crfsuite\n",
            "  Using cached python_crfsuite-0.9.9-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.9/dist-packages (1.3.6)\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (0.17.1)\n",
            "Requirement already satisfied: sastrawi in /usr/local/lib/python3.9/dist-packages (1.0.1)\n",
            "Collecting sklearn-pycrfsuite\n",
            "  Using cached sklearn_pycrfsuite-0.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (23.0)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy) (8.1.9)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.27.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.1.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.22.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.12)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.0.8)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy) (6.3.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (3.3.0)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy) (2.4.6)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy) (1.10.7)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy) (0.10.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy) (67.6.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.9/dist-packages (from sklearn-pycrfsuite) (1.16.0)\n",
            "Collecting python-crfsuite-extension\n",
            "  Using cached python-crfsuite-extension-0.9.7.tar.gz (485 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.9/dist-packages (from sklearn-pycrfsuite) (0.8.10)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy) (0.7.9)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy) (2.1.2)\n",
            "Building wheels for collected packages: python-crfsuite-extension\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py bdist_wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Building wheel for python-crfsuite-extension (setup.py) ... \u001b[?25lerror\n",
            "\u001b[31m  ERROR: Failed building wheel for python-crfsuite-extension\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[?25h  Running setup.py clean for python-crfsuite-extension\n",
            "Failed to build python-crfsuite-extension\n",
            "Installing collected packages: python-crfsuite-extension, python-crfsuite, sklearn-pycrfsuite, spacy\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31m×\u001b[0m \u001b[32mRunning setup.py install for python-crfsuite-extension\u001b[0m did not run successfully.\n",
            "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31m╰─>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Running setup.py install for python-crfsuite-extension ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1mlegacy-install-failure\u001b[0m\n",
            "\n",
            "\u001b[31m×\u001b[0m Encountered error while trying to install package.\n",
            "\u001b[31m╰─>\u001b[0m python-crfsuite-extension\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
            "\u001b[1;36mhint\u001b[0m: See above for output from the failure.\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: unidecode in /usr/local/lib/python3.9/dist-packages (1.3.6)\n",
            "Requirement already satisfied: twython in /usr/local/lib/python3.9/dist-packages (3.9.1)\n",
            "Requirement already satisfied: tweepy in /usr/local/lib/python3.9/dist-packages (4.13.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (4.12.2)\n",
            "Requirement already satisfied: tika in /usr/local/lib/python3.9/dist-packages (2.6.0)\n",
            "Requirement already satisfied: requests>=2.1.0 in /usr/local/lib/python3.9/dist-packages (from twython) (2.27.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.9/dist-packages (from twython) (1.3.1)\n",
            "Requirement already satisfied: oauthlib<4,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from tweepy) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4) (2.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tika) (67.6.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->twython) (3.4)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->twython) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->twython) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.1.0->twython) (1.26.15)\n",
            "2023-04-19 14:28:24.553244: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "2023-04-19 14:28:38.324887: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'xx' are deprecated. Please use the\n",
            "full pipeline package name 'xx_ent_wiki_sm' instead.\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xx-ent-wiki-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/xx_ent_wiki_sm-3.5.0/xx_ent_wiki_sm-3.5.0-py3-none-any.whl (11.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.1/11.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from xx-ent-wiki-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->xx-ent-wiki-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('xx_ent_wiki_sm')\n",
            "2023-04-19 14:28:52.321240: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.9/dist-packages (from en-core-web-sm==3.5.0) (3.5.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.6.1)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.6)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.8)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.0)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.9)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.7)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.9/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.1)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.9/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.5.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2022.12.7)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.0.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.9/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.9)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.9/dist-packages (from typer<0.8.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.2)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n"
          ]
        }
      ],
      "source": [
        "import warnings; warnings.simplefilter('ignore')\n",
        "import nltk\n",
        "\n",
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "    !wget https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/taudataDDGsna.py\n",
        "    !mkdir data\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/contoh.pdf\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/slang.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_id.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/stopwords_en.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/kata_dasar.txt\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-ind-def.tab\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/wn-msa-all.tab\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/ind_SA.csv\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/all_indo_man_tag_corpus_model.crf.tagger\n",
        "\n",
        "    !pip install --upgrade spacy python-crfsuite unidecode textblob sastrawi sklearn-pycrfsuite\n",
        "    !pip install --upgrade unidecode twython tweepy beautifulsoup4 tika\n",
        "    !python -m spacy download en\n",
        "    !python -m spacy download xx\n",
        "    !python -m spacy download en_core_web_sm\n",
        "    nltk.download('popular')\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "    print(\"Running the code locally, please make sure all the python module versions agree with colab environment and all data/assets downloaded\")"
      ],
      "id": "24430ad1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "242cea71",
        "outputId": "64b5b5a5-b6ac-459e-a874-0cb48bd3c095"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ],
      "source": [
        "import taudataDDGsna as tau\n",
        "import tweepy, json, urllib.request, requests\n",
        "from urllib.request import Request, urlopen\n",
        "from twython import TwythonStreamer\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from tqdm import tqdm\n",
        "\"Done\""
      ],
      "id": "242cea71"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2929d00"
      },
      "source": [
        "<h2 id=\"Aturan-twitter\">Aturan, bentuk data, &amp; error codes twitter</h2>\n",
        "\n",
        "<ol>\n",
        "\t<li>\n",
        "\t<p><a href=\"https://dev.twitter.com/rest/public/rate-limiting\" target=\"_blank\">https://</a><a href=\"https://dev.twitter.com/rest/public/rate-limiting\" target=\"_blank\">dev.twitter.com/rest/public/rate-limiting</a></p>\n",
        "\t</li>\n",
        "\t<li>\n",
        "\t<p><a href=\"https://dev.twitter.com/overview/terms/agreement-and-policy\" target=\"_blank\">https://dev.twitter.com/overview/terms/agreement-and-policy</a></p>\n",
        "\t</li>\n",
        "\t<li>\n",
        "\t<p><a href=\"https://dev.twitter.com/overview/api/response-codes\" target=\"_blank\">https://</a><a href=\"https://dev.twitter.com/overview/api/response-codes\" target=\"_blank\">dev.twitter.com/overview/api/response-codes</a></p>\n",
        "\t</li>\n",
        "\t<li>\n",
        "\t<p><a href=\"https://dev.twitter.com/overview/api/tweets\" target=\"_blank\">https://</a><a href=\"https://dev.twitter.com/overview/api/tweets\" target=\"_blank\">dev.twitter.com/overview/api/tweets</a></p>\n",
        "\t</li>\n",
        "</ol>"
      ],
      "id": "c2929d00"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "1a5b56cb",
        "outputId": "7c1fb10e-e78d-41a2-986c-5c3a265a2fc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "# Contoh API Keys (Sesuaikan dengan API keys masing-masing)\n",
        "Ck = 'p76aa3SQdGXG6KlOFB2rlEYN8' # consumer_key\n",
        "Cs = '7QY41F7LK449lKVUoi1sKlZidq6ALYVh4FEKQj2Ph6XmT4IN7N' # consumer_secret\n",
        "At = '529202222-MB1NLjJGxeZA6gKiiDFaHrPMVdGid1oOp7ZwDXyL' # access_token\n",
        "As = '1Yali9pzlbHyMRq5ta5FAPu1KQ4r2UsS6ujZGfXbNQxFo' # access_secret\n",
        "\n",
        "'Done'"
      ],
      "id": "1a5b56cb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c29cc633",
        "outputId": "270b08ff-b320-4961-c020-10555a7cfa02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome \"Nadila\" you are now connected to twitter server\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "\n",
        "auth = tweepy.auth.OAuthHandler(Ck, Cs)\n",
        "auth.set_access_token(At, As)\n",
        "api = tweepy.API(auth, wait_on_rate_limit=True, timeout=180, retry_count=5, retry_delay=3)\n",
        "usr_ = api.verify_credentials()\n",
        "print('Welcome \"{}\" you are now connected to twitter server'.format(usr_.name))"
      ],
      "id": "c29cc633"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3fc66ade",
        "outputId": "0b7c5b5a-1444-4408-a5f7-39405848f124"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done! ... Silahkan cek timeline twitter anda.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Kita bisa post, delete, follow, like, reply, retweet, dsb.\n",
        "# WARNING ... Status harus dibedakan, jika tidak akan gagal karena twitter mendeteksi status duplikat.\n",
        "\n",
        "status = \"Happy me\"\n",
        "t = api.update_status(status)\n",
        "# Silahkan cek timeline setelah ini\n",
        "\"Done! ... Silahkan cek timeline twitter anda.\""
      ],
      "id": "3fc66ade"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "71b21be9",
        "scrolled": true,
        "outputId": "d77cffc3-8448-4d9a-caa1-17b4d27f116b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# https://www.latlong.net/convert-address-to-lat-long.html\n",
        "\n",
        "alamat = \"Seoul, South Korea\"\n",
        "lat = '37.532600'\n",
        "lon = '127.024612'\n",
        "\n",
        "radius = '10000km'\n",
        "Geo = ','.join([lat, lon, radius])\n",
        "\n",
        "qry = '\"Me Too movement korean\" OR \"me too movement in south korea'\n",
        "#qry = '\"feminist korea\" OR \"anti feminist korea\"'\n",
        "N = 100 # jumlah N tweet \"terkini\" yang ingin diambil\n",
        "T = []\n",
        "for post in tqdm(tweepy.Cursor(api.search_tweets, q=qry, lang='en', tweet_mode='extended', since_id='2018-01-01').items(N)):\n",
        "    T.append(post)\n",
        "\n",
        "\"Done\""
      ],
      "id": "71b21be9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "id": "e843fd6d",
        "outputId": "b33b4a71-f4ff-447a-b0b0-e802e0bc89ec"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-78-3f9ac391b701>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mT\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_json\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "T[0]._json"
      ],
      "id": "e843fd6d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e7863e2",
        "outputId": "fbb8171d-7ad1-4c25-c01e-a05f366578eb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Berhasil mendapatkan 11 tweets\n"
          ]
        }
      ],
      "source": [
        "# T bukan sekedar list of tweets\n",
        "tweet = [t._json for t in T]\n",
        "print('Berhasil mendapatkan {} tweets'.format(len(tweet)))"
      ],
      "id": "8e7863e2"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4af0d114",
        "outputId": "ec92b7f5-2b81-42ea-8565-993d0d8e8f1f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'contributors': None,\n",
              " 'coordinates': None,\n",
              " 'created_at': 'Sat Jun 11 02:35:48 +0000 2022',\n",
              " 'display_text_range': [0, 140],\n",
              " 'entities': {'hashtags': [],\n",
              "  'symbols': [],\n",
              "  'urls': [],\n",
              "  'user_mentions': [{'id': 1215268532532834304,\n",
              "    'id_str': '1215268532532834304',\n",
              "    'indices': [3, 15],\n",
              "    'name': 'Balvyah',\n",
              "    'screen_name': 'BalvyHaddad'},\n",
              "   {'id': 1516416251572244480,\n",
              "    'id_str': '1516416251572244480',\n",
              "    'indices': [17, 31],\n",
              "    'name': '🙏🙏🙏',\n",
              "    'screen_name': 'A1234567890ZQ'},\n",
              "   {'id': 1524694713651015680,\n",
              "    'id_str': '1524694713651015680',\n",
              "    'indices': [32, 48],\n",
              "    'name': '🇮🇩🇵🇸JOHAN-ISWAHYUDI🇵🇸🇮🇩',\n",
              "    'screen_name': 'JohanIswahyud10'},\n",
              "   {'id': 2866140311,\n",
              "    'id_str': '2866140311',\n",
              "    'indices': [49, 60],\n",
              "    'name': 'Bhisma Yang Agung',\n",
              "    'screen_name': 'MahaBhisma'},\n",
              "   {'id': 1479144195721863170,\n",
              "    'id_str': '1479144195721863170',\n",
              "    'indices': [61, 75],\n",
              "    'name': 'Maul',\n",
              "    'screen_name': 'UnitedDay2022'}]},\n",
              " 'favorite_count': 0,\n",
              " 'favorited': False,\n",
              " 'full_text': 'RT @BalvyHaddad: @A1234567890ZQ @JohanIswahyud10 @MahaBhisma @UnitedDay2022 Kasian...\\nPagi2 treak2 mabok kecubung....\\n\\nMending kerja cari n…',\n",
              " 'geo': None,\n",
              " 'id': 1535450697453383681,\n",
              " 'id_str': '1535450697453383681',\n",
              " 'in_reply_to_screen_name': None,\n",
              " 'in_reply_to_status_id': None,\n",
              " 'in_reply_to_status_id_str': None,\n",
              " 'in_reply_to_user_id': None,\n",
              " 'in_reply_to_user_id_str': None,\n",
              " 'is_quote_status': False,\n",
              " 'lang': 'in',\n",
              " 'metadata': {'iso_language_code': 'in', 'result_type': 'recent'},\n",
              " 'place': None,\n",
              " 'retweet_count': 1,\n",
              " 'retweeted': False,\n",
              " 'retweeted_status': {'contributors': None,\n",
              "  'coordinates': None,\n",
              "  'created_at': 'Sat Jun 11 02:21:17 +0000 2022',\n",
              "  'display_text_range': [59, 187],\n",
              "  'entities': {'hashtags': [],\n",
              "   'symbols': [],\n",
              "   'urls': [],\n",
              "   'user_mentions': [{'id': 1516416251572244480,\n",
              "     'id_str': '1516416251572244480',\n",
              "     'indices': [0, 14],\n",
              "     'name': '🙏🙏🙏',\n",
              "     'screen_name': 'A1234567890ZQ'},\n",
              "    {'id': 1524694713651015680,\n",
              "     'id_str': '1524694713651015680',\n",
              "     'indices': [15, 31],\n",
              "     'name': '🇮🇩🇵🇸JOHAN-ISWAHYUDI🇵🇸🇮🇩',\n",
              "     'screen_name': 'JohanIswahyud10'},\n",
              "    {'id': 2866140311,\n",
              "     'id_str': '2866140311',\n",
              "     'indices': [32, 43],\n",
              "     'name': 'Bhisma Yang Agung',\n",
              "     'screen_name': 'MahaBhisma'},\n",
              "    {'id': 1479144195721863170,\n",
              "     'id_str': '1479144195721863170',\n",
              "     'indices': [44, 58],\n",
              "     'name': 'Maul',\n",
              "     'screen_name': 'UnitedDay2022'}]},\n",
              "  'favorite_count': 1,\n",
              "  'favorited': False,\n",
              "  'full_text': '@A1234567890ZQ @JohanIswahyud10 @MahaBhisma @UnitedDay2022 Kasian...\\nPagi2 treak2 mabok kecubung....\\n\\nMending kerja cari nafkah yg baik yaa\\nIngat, harga2 sembako, listrik, bbm naik semua.',\n",
              "  'geo': None,\n",
              "  'id': 1535447046722752512,\n",
              "  'id_str': '1535447046722752512',\n",
              "  'in_reply_to_screen_name': 'A1234567890ZQ',\n",
              "  'in_reply_to_status_id': 1535441033474895872,\n",
              "  'in_reply_to_status_id_str': '1535441033474895872',\n",
              "  'in_reply_to_user_id': 1516416251572244480,\n",
              "  'in_reply_to_user_id_str': '1516416251572244480',\n",
              "  'is_quote_status': False,\n",
              "  'lang': 'in',\n",
              "  'metadata': {'iso_language_code': 'in', 'result_type': 'recent'},\n",
              "  'place': None,\n",
              "  'retweet_count': 1,\n",
              "  'retweeted': False,\n",
              "  'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              "  'truncated': False,\n",
              "  'user': {'contributors_enabled': False,\n",
              "   'created_at': 'Thu Jan 09 13:46:38 +0000 2020',\n",
              "   'default_profile': True,\n",
              "   'default_profile_image': False,\n",
              "   'description': 'Yaa Robby Please Forgive Us.                                                     \\n\\n#SikDeKangen \\n\\n#GakFollowAkunPorno @Rourin02  🇮🇩 ❤ 🇩🇪',\n",
              "   'entities': {'description': {'urls': []}},\n",
              "   'favourites_count': 46815,\n",
              "   'follow_request_sent': False,\n",
              "   'followers_count': 9795,\n",
              "   'following': False,\n",
              "   'friends_count': 4742,\n",
              "   'geo_enabled': False,\n",
              "   'has_extended_profile': False,\n",
              "   'id': 1215268532532834304,\n",
              "   'id_str': '1215268532532834304',\n",
              "   'is_translation_enabled': False,\n",
              "   'is_translator': False,\n",
              "   'lang': None,\n",
              "   'listed_count': 3,\n",
              "   'location': '',\n",
              "   'name': 'Balvyah',\n",
              "   'notifications': False,\n",
              "   'profile_background_color': 'F5F8FA',\n",
              "   'profile_background_image_url': None,\n",
              "   'profile_background_image_url_https': None,\n",
              "   'profile_background_tile': False,\n",
              "   'profile_banner_url': 'https://pbs.twimg.com/profile_banners/1215268532532834304/1641261604',\n",
              "   'profile_image_url': 'http://pbs.twimg.com/profile_images/1522616372991172608/9t5gKmGX_normal.jpg',\n",
              "   'profile_image_url_https': 'https://pbs.twimg.com/profile_images/1522616372991172608/9t5gKmGX_normal.jpg',\n",
              "   'profile_link_color': '1DA1F2',\n",
              "   'profile_sidebar_border_color': 'C0DEED',\n",
              "   'profile_sidebar_fill_color': 'DDEEF6',\n",
              "   'profile_text_color': '333333',\n",
              "   'profile_use_background_image': True,\n",
              "   'protected': False,\n",
              "   'screen_name': 'BalvyHaddad',\n",
              "   'statuses_count': 22547,\n",
              "   'time_zone': None,\n",
              "   'translator_type': 'none',\n",
              "   'url': None,\n",
              "   'utc_offset': None,\n",
              "   'verified': False,\n",
              "   'withheld_in_countries': []}},\n",
              " 'source': '<a href=\"http://twitter.com/download/android\" rel=\"nofollow\">Twitter for Android</a>',\n",
              " 'truncated': False,\n",
              " 'user': {'contributors_enabled': False,\n",
              "  'created_at': 'Fri Nov 07 19:06:55 +0000 2014',\n",
              "  'default_profile': False,\n",
              "  'default_profile_image': False,\n",
              "  'description': '#GakFollowPorno #AntiOportunis #AntiPembohong #AntiLGBTQ  Cebong blok, Gak santun blok, PL blok, Syiah jegurno septitank. Veritas numquam perit',\n",
              "  'entities': {'description': {'urls': []},\n",
              "   'url': {'urls': [{'display_url': 'mahabhisma.wordpress.com',\n",
              "      'expanded_url': 'http://mahabhisma.wordpress.com',\n",
              "      'indices': [0, 23],\n",
              "      'url': 'https://t.co/7acD9ZZcef'}]}},\n",
              "  'favourites_count': 18049,\n",
              "  'follow_request_sent': False,\n",
              "  'followers_count': 2013,\n",
              "  'following': False,\n",
              "  'friends_count': 3982,\n",
              "  'geo_enabled': True,\n",
              "  'has_extended_profile': True,\n",
              "  'id': 2866140311,\n",
              "  'id_str': '2866140311',\n",
              "  'is_translation_enabled': False,\n",
              "  'is_translator': False,\n",
              "  'lang': None,\n",
              "  'listed_count': 5,\n",
              "  'location': 'Fort George G. Meade, Maryland',\n",
              "  'name': 'Bhisma Yang Agung',\n",
              "  'notifications': False,\n",
              "  'profile_background_color': 'C0DEED',\n",
              "  'profile_background_image_url': 'http://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "  'profile_background_image_url_https': 'https://abs.twimg.com/images/themes/theme1/bg.png',\n",
              "  'profile_background_tile': True,\n",
              "  'profile_banner_url': 'https://pbs.twimg.com/profile_banners/2866140311/1653041451',\n",
              "  'profile_image_url': 'http://pbs.twimg.com/profile_images/590176923260559360/O08MIFpG_normal.jpg',\n",
              "  'profile_image_url_https': 'https://pbs.twimg.com/profile_images/590176923260559360/O08MIFpG_normal.jpg',\n",
              "  'profile_link_color': '0084B4',\n",
              "  'profile_sidebar_border_color': '000000',\n",
              "  'profile_sidebar_fill_color': 'DDEEF6',\n",
              "  'profile_text_color': '333333',\n",
              "  'profile_use_background_image': True,\n",
              "  'protected': False,\n",
              "  'screen_name': 'MahaBhisma',\n",
              "  'statuses_count': 26674,\n",
              "  'time_zone': None,\n",
              "  'translator_type': 'none',\n",
              "  'url': 'https://t.co/7acD9ZZcef',\n",
              "  'utc_offset': None,\n",
              "  'verified': False,\n",
              "  'withheld_in_countries': []}}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Data pertama\n",
        "tweet[0]"
      ],
      "id": "4af0d114"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f629c232",
        "outputId": "71f176bb-6d4a-4603-9606-5c420bb6cfda"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Tue Apr 11 18:52:57 +0000 2023',\n",
              " 'Ye T-Series wala haii ?\\n\\nIska bhi #Metoo me naam aaya tha...\\n\\nAb BJP ki bhakti me bjp walo k album launch krta !! https://t.co/DQp6HSKvcM')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Datanya berbentuk JSON\n",
        "tweet[10]['created_at'], tweet[10]['full_text']"
      ],
      "id": "f629c232"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3a12b41e",
        "outputId": "7c3dc9c9-dad7-4ac6-c63d-e6f3b246fe60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet pertama oleh \"Ciput84725571\" : \"RT @SmashNewsCorp: Smash News - Industri plat merah belum menjual bahan bakar minyak( BBM) non- subsidi yang cocok dengan harga keekonomian…\"\n"
          ]
        }
      ],
      "source": [
        "# Contoh mengakses data spesifik pada tweet yang pertama:\n",
        "print('tweet pertama oleh \"{}\" : \"{}\"'.format(tweet[0]['user']['screen_name'],tweet[0]['full_text']))"
      ],
      "id": "3a12b41e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13da7fab"
      },
      "source": [
        "# <center><font color=\"blue\">Menyimpan hasil crawling (sederhana ke Text file berformat json)</font></center>"
      ],
      "id": "13da7fab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27919b88"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "def saveTweets(tweets, file='Tweets.json'): #in Json Format\n",
        "    with open(file, 'w') as f:\n",
        "        for t in tweets:\n",
        "            try:\n",
        "                f.write(json.dumps(t)+'\\n')\n",
        "            except:\n",
        "                pass"
      ],
      "id": "27919b88"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a03e46dd",
        "outputId": "2a06082a-3730-4f99-a22f-b3ff902ae4c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved to Tweets_2022.json\n"
          ]
        }
      ],
      "source": [
        "# Menyimpan hasil crawling twitter\n",
        "fileName = 'Tweets_2022.json'\n",
        "saveTweets(tweet, file=fileName)\n",
        "print('Saved to '+fileName)"
      ],
      "id": "a03e46dd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cab4f6c8"
      },
      "source": [
        "# <center><font color=\"blue\">Load Kembali?</font></center>"
      ],
      "id": "cab4f6c8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5b9b1004"
      },
      "outputs": [],
      "source": [
        "def loadTweets(file='Tweets.json'):\n",
        "    f=open(file,encoding='utf-8', errors ='ignore', mode='r')\n",
        "    T=f.readlines();f.close()\n",
        "    for i,t in enumerate(T):\n",
        "        T[i] = json.loads(t.strip())\n",
        "    return T"
      ],
      "id": "5b9b1004"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "50f6238c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6433967a-f316-4ffe-dd8c-8a8e8e31b68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet pertama oleh \"Ciput84725571\" : \"RT @SmashNewsCorp: Smash News - Industri plat merah belum menjual bahan bakar minyak( BBM) non- subsidi yang cocok dengan harga keekonomian…\"\n"
          ]
        }
      ],
      "source": [
        "# Me-load kembali jika (misal) analisa ingin dilakukan di lain waktu\n",
        "# Sengaja nama variabelnya saya bedakan (T2)\n",
        "T2 = loadTweets(file=fileName)\n",
        "print('tweet pertama oleh \"{}\" : \"{}\"'.format(T2[0]['user']['screen_name'],T2[0]['full_text']))"
      ],
      "id": "50f6238c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75f286cd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1508f81a-5012-48a2-dd7b-a34150e942c1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['RT @SmashNewsCorp: Smash News - Industri plat merah belum menjual bahan bakar minyak( BBM) non- subsidi yang cocok dengan harga keekonomian…',\n",
              " '@needtoplove DM aja',\n",
              " '@mlbbfess Ngisinya pertamax plus dia bukan premium',\n",
              " 'Ujan2 enak kali ya, main bertiga...\\n Lagi di reddoors nih, siapa tau ada yang mau joint.. \\n\\n#gaysemarang',\n",
              " '@UNSfess_ Mau diisi apa kak? Pertalite apa pertamax. Kalau Pertamax skrg lagi mahal.']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Contoh mengambil hanya data tweet\n",
        "D = [t['full_text'] for t in T2]\n",
        "D[:5] # 5 tweet pertama"
      ],
      "id": "75f286cd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8c32eaab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d27fa0d-e909-481b-92ba-0deceab52b99"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Setiap kita punya peran dalam pelestarian alam. Setiap orang bisa punya andil menyelamatkan bumi.\\n\\nSelamat Hari Lingkungan Hidup Sedunia https://t.co/bbhaJO72tw',\n",
              " 'Balap Formula E ini adalah tontonan yang semakin digemari di masa depan mengingat kian banyaknya pemakai mobil listrik. Ajang balap ini juga bagus untuk Indonesia yang akan membangun ekosistem kendaraan listrik. https://t.co/bOq9W7vQxl',\n",
              " 'Hari ini, kita menyaksikan langsung atau melalui tayangan televisi, gelaran balap 2022 Jakarta E-Prix di Sirkuit Formula E, Jakarta. Alhamdulillah semuanya berjalan lancar. \\n\\nSelamat kepada para pemenang. Semoga ke depan, lebih banyak lagi penyelenggaraan balap serupa Formula E. https://t.co/qUgVWwk5rX',\n",
              " 'Semua milik Allah SWT dan hanya kepadaNya kita akan kembali. \\n\\nTurut berbelasungkawa atas berpulangnya ananda Emmeril Kahn Mumtadz, semoga seluruh keluarga Bapak Ridwan Kamil diberikan ketabahan dan keikhlasan. https://t.co/lOeBmciGQj',\n",
              " 'Menonton pacuan kuda yang seru di lapangan Rihi Eti Prailiu, Sumba Timur, siang tadi. Lomba ini diikuti ratusan ekor kuda. https://t.co/BI10mOoCqM',\n",
              " 'Meninjau pengolahan hasil panen sorgum, ikut menanam bibit sorgum dengan alat tanam biji benih, dan menyaksikan panen sorgum di PT Sorghum Indonesia di Sumba Timur, NTT. \\n\\nDi tengah ancaman krisis pangan dunia, kita perlu rencana besar memanfaatkan alternatif bahan pangan. https://t.co/BYtFLNcY2O',\n",
              " 'Konser kebangsaan digelar semalam di Stadion Marilonga Ende dengan menghadirkan sejumlah musisi Indonesia untuk menghibur masyarakat. Di antaranya, ada Slank yang menyanyikan 17 lagu dan Kla Project yang membawakan delapan lagu. https://t.co/yAgvq5M47U',\n",
              " 'Dari bambu-bambu ini, aneka produk dapat dihasilkan, seperti yang saya lihat sendiri. Ada rumah bambu lestari, sepeda bambu yang dinamai Spedagi, juga bambu laminasi yang dapat digunakan untuk tiang, dinding, hingga lantai bangunan. https://t.co/9BQZbDFK1L',\n",
              " 'Berkunjung ke  Kampus Bambu Turetogo di Ngada, kemarin, saya bertemu dengan Mama-mama Bambu, ibu-ibu dari 7 kabupaten di Flores, NTT. \\n\\nMereka datang ke kampus ini untuk belajar mengenai cara pembibitan bambu di kampus ini, pembesaran, hingga pengelolaan hutan bambu lestari. https://t.co/NfMZ3RLfaH',\n",
              " 'Blusukan malam di Ende.\\n\\nhttps://t.co/J6705FQW20',\n",
              " 'Dari Ende, saya dan Ibu Negara ke Kab. Ngada. Kami disambut dengan tari Ja’i Bajawa, dan sepanjang jalan terlihat meriah. Rupanya, inilah kunjungan pertama Presiden RI ke Ngada.   \\n\\nDi Kab. Ngada, saya menyerahkan bantuan sosial di Pasar Bobou dan meninjau Kampus Bambu Turetogo. https://t.co/3cUSmimU8g',\n",
              " 'Pasar Mbongawani di Ende begitu ramai oleh pedagang dan masyarakat saat saya dan Ibu Negara datang ke sana, pagi tadi.\\n\\nSaya sempat membagikan sejumlah bantuan sosial bagi pedagang dan masyarakat penerima manfaat, dan Ibu Negara berbelanja cabai. https://t.co/4WfOkENkqT',\n",
              " 'Terima kasih atas penerimaan yang hangat masyarakat NTT, khususnya masyarakat Ende, kepada saya, Ibu Negara, dan rombongan.\\n\\nSaya yang hari ini mengenakan pakaian adat Ragi Lambu Luka Lesu, juga dianugerahi gelar adat Mosalaki Ulu Beu Eko Bewa, pemimpin wilayah seluruh Indonesia. https://t.co/iNWBy2161T',\n",
              " 'Dari kota Ende, tempat  Bung Karno merenungkan dan merumuskan Pancasila, saya mengajak seluruh anak bangsa di manapun berada untuk bersama-sama membumikan Pancasila dan mengaktualisasikan nilai-nilai luhur Pancasila dalam kehidupan bermasyarakat, berbangsa dan bernegara. https://t.co/1cu9jMz0FJ',\n",
              " 'Pada masa-masa pengasingannya di Ende, sebelum kemerdekaan, Bung Karno kerap datang dan duduk untuk berkontemplasi di tempat ini. \\n\\n\"Di kota ini kutemukan lima butir mutiara. Di bawah pohon sukun ini pula kurenungkan nilai-nilai luhur Pancasila,\" kata Bung Karno suatu ketika. https://t.co/NGHfqMX5H0']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Mari kita coba #1\n",
        "topic = 'from:jokowi'\n",
        "T = api.search_tweets(q=topic, lang='id', tweet_mode = 'extended')\n",
        "tweet = [t._json for t in T]\n",
        "isiTweet = [t['full_text'] for t in tweet]\n",
        "isiTweet"
      ],
      "id": "8c32eaab"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12ace4e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6599861c-2d94-423b-8469-fdde1971cb28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# https://www.latlong.net/convert-address-to-lat-long.html\n",
        "\n",
        "alamat = \"Graha Cipta 5, Jejalen Jaya, Tambun Utara, Bekasi\"\n",
        "lat = '-6.236690'\n",
        "lon = '107.063560'\n",
        "\n",
        "\"Done\""
      ],
      "id": "12ace4e1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "52dd3506",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3487e2d-c774-4fa0-e409-1ca839849ed4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[datetime.datetime(2022, 6, 5, 10, 53, 1, tzinfo=datetime.timezone.utc), b'@Aldoaria @FOOD_FESS Seblak didieu ewh ngeunah2 na acan beda jeung jieunan indung sorangan', 747725422339698688, None]\n",
            "[datetime.datetime(2022, 6, 5, 4, 40, 28, tzinfo=datetime.timezone.utc), b'Mie seblak ajalah yak https://t.co/bp11PYZeSF', 941497184289095680, None]\n",
            "[datetime.datetime(2022, 6, 4, 17, 47, 40, tzinfo=datetime.timezone.utc), b'@fosilmikro mereka uangnya habis beli seblak ketimbang deodorant. Padahal deodorant sama serbuk tawas buat mandi murah lho.', 1361422247978704896, None]\n",
            "[datetime.datetime(2022, 6, 4, 15, 42, 28, tzinfo=datetime.timezone.utc), b'begah bgt abis makan seblak 2 mangkok \\xf0\\x9f\\x98\\xac', 1214485917307588608, None]\n",
            "[datetime.datetime(2022, 6, 4, 14, 50, 43, tzinfo=datetime.timezone.utc), b'Seblak kasih nasi juga belum mempan #kenyangnya \\xf0\\x9f\\x98\\xb9\\xf0\\x9f\\x98\\x8c', 130684283, None]\n",
            "[datetime.datetime(2022, 6, 4, 13, 24, 58, tzinfo=datetime.timezone.utc), b'cowok kok ga pernah bm seblak ya??', 1080828467074093056, None]\n",
            "[datetime.datetime(2022, 6, 4, 11, 53, 50, tzinfo=datetime.timezone.utc), b'malmink kemana muts? ak dirumah aja, baru pulang krna td sore uda pergi &amp; skrg mau gofood seblak hoho\\xf0\\x9f\\x99\\x87\\xf0\\x9f\\x8f\\xbb\\xe2\\x80\\x8d\\xe2\\x99\\x80\\xef\\xb8\\x8f\\xf0\\x9f\\x92\\xa8', 1151674077418885120, None]\n",
            "[datetime.datetime(2022, 6, 4, 11, 2, 53, tzinfo=datetime.timezone.utc), b'@FOODFESS2 cilor, seblak, batagor', 1528786010003632128, None]\n",
            "[datetime.datetime(2022, 6, 4, 11, 2, 15, tzinfo=datetime.timezone.utc), b'@bekasibase makan seblak, jalan jalan metime gitu kak', 1528786010003632128, None]\n",
            "[datetime.datetime(2022, 6, 4, 10, 58, 27, tzinfo=datetime.timezone.utc), b'Sophia Latjuba, kira2 prnah mkn seblak ga ya, prnah mkn indomie 2 pke nasi ga ya, prnah mkn naspad dibungkus eh pas\\xe2\\x80\\xa6 https://t.co/Dfn4i2I6b7', 539640284, None]\n",
            "[datetime.datetime(2022, 6, 4, 10, 17, 11, tzinfo=datetime.timezone.utc), b'@prastianto__ mau seblak', 1158475166352994305, None]\n",
            "[datetime.datetime(2022, 6, 4, 10, 2, 4, tzinfo=datetime.timezone.utc), b'Ko bisa sih seblak enak', 1439808067, None]\n",
            "[datetime.datetime(2022, 6, 4, 9, 15, 40, tzinfo=datetime.timezone.utc), b'Banyakan makan seblak sama lid-lidian ga sih kita wkwkwkwkwk \\xf0\\x9f\\xa4\\xa3\\xf0\\x9f\\xa4\\xa3 https://t.co/35z0RGBG1h', 539640284, None]\n",
            "[datetime.datetime(2022, 6, 4, 8, 18, 47, tzinfo=datetime.timezone.utc), b'si paling males keluar sampe seblak aja lu grabfood in dutttt\\xf0\\x9f\\xa4\\xa7', 177830343, None]\n",
            "[datetime.datetime(2022, 6, 4, 4, 53, 28, tzinfo=datetime.timezone.utc), b'@halleluhellyeah Sebenernya abis nikah cuma takut \"Ready basreng cilok seblak nya kakak\"', 3321921738, None]\n",
            "[datetime.datetime(2022, 6, 3, 15, 31, 21, tzinfo=datetime.timezone.utc), b'Seblak, Dimsum, Bihlor https://t.co/7FhwHZuY1i', 722711756053868546, None]\n",
            "[datetime.datetime(2022, 6, 3, 15, 30, 9, tzinfo=datetime.timezone.utc), b'Seblak, Bakso, Pangsit https://t.co/hXGLZSper7', 722711756053868546, None]\n",
            "[datetime.datetime(2022, 6, 3, 12, 5, 6, tzinfo=datetime.timezone.utc), b'Anying pengen seblak wkwkw', 440352170, None]\n",
            "[datetime.datetime(2022, 6, 3, 12, 3, 18, tzinfo=datetime.timezone.utc), b'@scarletwitcheez @bdngfess Mau dikasih seblak apa naga?', 321198410, None]\n",
            "[datetime.datetime(2022, 6, 3, 11, 21, 28, tzinfo=datetime.timezone.utc), b'Percobaan hari ini jualan seblak dan kwetiau goreng, alhamdulillah habis', 238933901, None]\n",
            "[datetime.datetime(2022, 6, 3, 10, 25, 55, tzinfo=datetime.timezone.utc), b'hbs makan seblak perut gue panas\\xf0\\x9f\\x98\\xad', 1291824029532172289, None]\n",
            "[datetime.datetime(2022, 6, 3, 9, 57, 53, tzinfo=datetime.timezone.utc), b'@yourcrustyyy Cot bgt seblak gue manaaaaaaaa', 1364578065607663616, None]\n",
            "[datetime.datetime(2022, 6, 3, 6, 38, 13, tzinfo=datetime.timezone.utc), b'Hayang seblak\\xf0\\x9f\\x98\\x81', 1384581796218630156, None]\n",
            "[datetime.datetime(2022, 6, 3, 0, 11, 46, tzinfo=datetime.timezone.utc), b'@bayu_joo Seblak, kopi', 527332213, None]\n",
            "[datetime.datetime(2022, 6, 2, 17, 3, 7, tzinfo=datetime.timezone.utc), b'Mau sombong saya sdh tidk pernah jajan seblak. Wkwk pernah keracunan. \\xf0\\x9f\\x98\\x82', 404637644, None]\n",
            "[datetime.datetime(2022, 6, 2, 16, 19, 7, tzinfo=datetime.timezone.utc), b'ini mah bukan naga, tapi kuda makan seblak level 10 https://t.co/eRDB98Uv2D', 243623320, None]\n",
            "[datetime.datetime(2022, 6, 2, 14, 25, 50, tzinfo=datetime.timezone.utc), b'Meuni mantep kiyeu seblak seafood', 2859580688, None]\n",
            "[datetime.datetime(2022, 6, 2, 14, 5, 56, tzinfo=datetime.timezone.utc), b'Yg di tunggu gak sampe sampe -_- beli seblak aja kali ya', 354641187, None]\n",
            "[datetime.datetime(2022, 6, 2, 13, 41, 20, tzinfo=datetime.timezone.utc), b'@zh0nglifucker Makan seblak adalah kunci', 399316331, None]\n",
            "[datetime.datetime(2022, 6, 2, 12, 53, 52, tzinfo=datetime.timezone.utc), b'Bm seblak:v', 1179049295074316288, None]\n",
            "[datetime.datetime(2022, 6, 2, 12, 39, 26, tzinfo=datetime.timezone.utc), b'cuacanya enak bgt ingin2 gmn gtu \\xf0\\x9f\\x98\\xa9\\njd pengen seblak\\xf0\\x9f\\x98\\xa9', 272299299, None]\n",
            "[datetime.datetime(2022, 6, 2, 12, 27, 58, tzinfo=datetime.timezone.utc), b'@wh0sheree gue kira ini seblak', 816417752097263617, None]\n",
            "[datetime.datetime(2022, 6, 2, 8, 19, 55, tzinfo=datetime.timezone.utc), b'@_FWZ_ @Udinesia7 @unisa_yogya Wanjir ..seblak..', 981848207029297152, None]\n",
            "[datetime.datetime(2022, 6, 2, 6, 47, 50, tzinfo=datetime.timezone.utc), b'3 hari berturut2 makan pedes, pentol si cabe, mie gacoan, seblak beuhh skrng menikmati boker boker trs\\xf0\\x9f\\xa5\\xb2\\xf0\\x9f\\xa5\\xb2', 3301577546, None]\n",
            "[datetime.datetime(2022, 6, 1, 13, 18, 9, tzinfo=datetime.timezone.utc), b'Seblak = boti https://t.co/GtFrG26l2L', 2292749588, None]\n",
            "[datetime.datetime(2022, 6, 1, 11, 52, 3, tzinfo=datetime.timezone.utc), b'@YourMine56 yg enak tukang seblak apa seblak nya?', 1324333347816964096, None]\n",
            "[datetime.datetime(2022, 6, 1, 11, 31, 49, tzinfo=datetime.timezone.utc), b'Makan seblak enak kayanya ya', 4853323513, None]\n",
            "[datetime.datetime(2022, 6, 1, 10, 18, 19, tzinfo=datetime.timezone.utc), b'pc makan seblak jeletot https://t.co/VwKu6hA372', 971845464, None]\n",
            "[datetime.datetime(2022, 6, 1, 8, 8, 12, tzinfo=datetime.timezone.utc), b'@ArisWila Bocah maennya ya ketemu bocah\\nBakal rame teriak teriak minta seblak sosis', 132724737, None]\n",
            "[datetime.datetime(2022, 6, 1, 7, 47, 16, tzinfo=datetime.timezone.utc), b'@Askrlfess Seblak', 1486261505901600773, None]\n",
            "[datetime.datetime(2022, 6, 1, 5, 48, 7, tzinfo=datetime.timezone.utc), b'@prastianto__ @tanyakanrl Seblak', 1402145537965453314, None]\n",
            "[datetime.datetime(2022, 6, 1, 5, 3, 40, tzinfo=datetime.timezone.utc), b'nominal uang nya, seandainya gua di kasih uang segitu pasti gua uda mikir buat ngabisin tu uang karna nominal nya s\\xe2\\x80\\xa6 https://t.co/HUsu8rfCZv', 1239597511515365376, None]\n",
            "[datetime.datetime(2022, 6, 1, 2, 10, 50, tzinfo=datetime.timezone.utc), b'@dugyundugyun @FOODFESS2 Disini kaa, ngga terlalu jauh dari kosan aku\\nhttps://t.co/d4baA94rvi', 1532599406, None]\n",
            "[datetime.datetime(2022, 5, 31, 16, 21, 59, tzinfo=datetime.timezone.utc), b'kaum seblak mundur https://t.co/cK2fECGemc', 1327332701163044864, None]\n",
            "[datetime.datetime(2022, 5, 31, 15, 32, 52, tzinfo=datetime.timezone.utc), b'@be_robe4 HAHAHAHAHHA GANTI AH YG SEBLAK', 1191615818854850561, None]\n",
            "[datetime.datetime(2022, 5, 31, 14, 26, 35, tzinfo=datetime.timezone.utc), b'@KhoirulAnammme @RajuSyaharany @recehtapisayng Iya gausah jajanin seblak. Orang maunya dunkin donuts wkwk', 1494696737578967041, None]\n",
            "[datetime.datetime(2022, 5, 31, 13, 51, 49, tzinfo=datetime.timezone.utc), b'@cimolnya_qaqa Monmaap, tapi fotonya bukan seblak :(', 726432451891863552, None]\n",
            "[datetime.datetime(2022, 5, 31, 10, 32, 36, tzinfo=datetime.timezone.utc), b'@ohmybeautybank Aku jg gatau nder, tp semenjak aku jaga pola makan terus ngurangin makanan sebangsa seblak, cilok,\\xe2\\x80\\xa6 https://t.co/RN8cYNeUtx', 1498911599855546371, None]\n",
            "[datetime.datetime(2022, 5, 31, 9, 25, 54, tzinfo=datetime.timezone.utc), b'lagi emosi gini enaknya makan seblak', 101441695, None]\n",
            "[datetime.datetime(2022, 5, 31, 7, 4, 5, tzinfo=datetime.timezone.utc), b'Agak risih sama cewe yang dikit\\xc2\\xb2 bilang : \"apa cuma gue yg ga bisa alisan, make up an, pake skincare, ga suka kpop,\\xe2\\x80\\xa6 https://t.co/zCLAodbL07', 2152337594, None]\n",
            "[datetime.datetime(2022, 5, 31, 6, 18, 34, tzinfo=datetime.timezone.utc), b'@FOODFESS2 Seblak mie https://t.co/RZyQI8aBRS', 3194677153, None]\n",
            "[datetime.datetime(2022, 5, 31, 5, 30, 45, tzinfo=datetime.timezone.utc), b'@FOODFESS2 Edisi seblak polosan https://t.co/NIVAq0M19s', 1335056697157537797, None]\n",
            "[datetime.datetime(2022, 5, 31, 2, 24, 3, tzinfo=datetime.timezone.utc), b'@ciiindyiii Kaya seblak enak bgt keknya\\xf0\\x9f\\x98\\x8d\\xf0\\x9f\\x98\\x8d\\xf0\\x9f\\x98\\x8d\\xf0\\x9f\\x98\\x8d', 801420668, None]\n",
            "[datetime.datetime(2022, 5, 30, 17, 13, tzinfo=datetime.timezone.utc), b'waaah 13k,\\nbeli seblak kembali 3rebu. https://t.co/K0MT7hhh3p', 1242472589143855105, None]\n",
            "[datetime.datetime(2022, 5, 30, 13, 48, 16, tzinfo=datetime.timezone.utc), b'@betchesh mau seblak', 1184417746190139393, None]\n",
            "[datetime.datetime(2022, 5, 30, 12, 5, 44, tzinfo=datetime.timezone.utc), b'@FoodBase_ Seblak ,mie ayam baso.', 236287735, None]\n",
            "[datetime.datetime(2022, 5, 30, 11, 38, 14, tzinfo=datetime.timezone.utc), b'*gue diem, trs mikir ini antara gue yg salah apa dia yg bener ya\\xf0\\x9f\\xa4\\x94*\\n *makasih yaa misuaku, lebih mentingin istrinya\\xe2\\x80\\xa6 https://t.co/7nvfUwB51b', 516075229, None]\n",
            "[datetime.datetime(2022, 5, 30, 11, 25, 37, tzinfo=datetime.timezone.utc), b'\\xf0\\x9f\\xa4\\xb5\\xf0\\x9f\\x8f\\xbb: kenapa?\\n\\xf0\\x9f\\x91\\xb0\\xf0\\x9f\\x8f\\xbb: *sinis* lagian dari tadi orang minta anterin beli seblak\\n\\xf0\\x9f\\xa4\\xb5\\xf0\\x9f\\x8f\\xbb: *langsung berdiri* ydh ayo kita beli.\\xe2\\x80\\xa6 https://t.co/dKUREuDJrB', 516075229, None]\n",
            "[datetime.datetime(2022, 5, 30, 8, 41, 14, tzinfo=datetime.timezone.utc), b'Hayang rujak, hayang seblak, hayang dahar wae da aing teu puguh\\xf0\\x9f\\xa5\\xb2', 1317080032041340928, None]\n",
            "[datetime.datetime(2022, 5, 30, 2, 51, tzinfo=datetime.timezone.utc), b'Geprek apa seblak yaa \\xf0\\x9f\\x98\\x95', 3557086273, None]\n",
            "[datetime.datetime(2022, 5, 29, 19, 58, 19, tzinfo=datetime.timezone.utc), b'@jentikthanos Doyannn pake nasii??? Kalo seblaknya aja sih gapapa, karna cowo ku juga suka seblak\\xf0\\x9f\\x98\\x82', 1397936268575608834, None]\n",
            "[datetime.datetime(2022, 5, 29, 14, 27, 42, tzinfo=datetime.timezone.utc), b'Ya namanya juga 300k sebulan. Jajan seblak di pertigaan aja udah girang', 1285738378017701888, None]\n",
            "[datetime.datetime(2022, 5, 29, 14, 22, 11, tzinfo=datetime.timezone.utc), b'@shaasyyll gatau ya, banyak yg bilang sih gitu \\xf0\\x9f\\x98\\xad mungkin cewenya keseringan makan seblak jadi wangi kencur', 1522957993318494208, None]\n",
            "[datetime.datetime(2022, 5, 29, 14, 21, 17, tzinfo=datetime.timezone.utc), b'@shaasyyll WKWKWKWK anjg lehernya bau seblak dong ?', 1522957993318494208, None]\n",
            "[datetime.datetime(2022, 5, 29, 13, 43, 57, tzinfo=datetime.timezone.utc), b'pginya mkn rujak, siang seblak, sore mkn nangka. yaa\\xe2\\x80\\x94 ya pantesss anj w mules2 ni mlm ((\\xe2\\x80\\x98:', 2992138556, None]\n",
            "[datetime.datetime(2022, 5, 29, 12, 35, 54, tzinfo=datetime.timezone.utc), b'mixue dateee. tinggal seblak date, pizza date, topokki date, ap lg y https://t.co/bOphHellUt', 1067454580185694208, None]\n",
            "[datetime.datetime(2022, 5, 29, 10, 54, 44, tzinfo=datetime.timezone.utc), b'@vitaryndt jangan jangan buat makan seblak', 380260210, None]\n",
            "[datetime.datetime(2022, 5, 29, 5, 49, 9, tzinfo=datetime.timezone.utc), b'@masdit_r Seblak enak kok', 1210812569570557958, None]\n",
            "[datetime.datetime(2022, 5, 29, 4, 33, 36, tzinfo=datetime.timezone.utc), b'@yerimienjuu bismillah.. buat jajan seblak special ama beli es kopi \\xf0\\x9f\\x98\\x81\\xf0\\x9f\\x98\\x81', 1444798247797608448, None]\n",
            "[datetime.datetime(2022, 5, 29, 3, 58, 54, tzinfo=datetime.timezone.utc), b'\"besok bikin lagi aja seblak, enak itu\" \"loh enak ini\" wksmskaj brp kali ya td nenek &amp; tante ak bilang enak.. BIKIN\\xe2\\x80\\xa6 https://t.co/s4fGGBDXO3', 1270568743953817600, None]\n",
            "[datetime.datetime(2022, 5, 28, 17, 23, 43, tzinfo=datetime.timezone.utc), b'Sekarang kalo maen udah paling bener jajan seblak samping rumah ayang ama nongkrong di puribeta-kreo aja. Dapet jaj\\xe2\\x80\\xa6 https://t.co/3u02PjXM8h', 261120009, None]\n",
            "[datetime.datetime(2022, 5, 28, 15, 39, 33, tzinfo=datetime.timezone.utc), b'@ameyrabella seblak enak', 1522957993318494208, None]\n",
            "[datetime.datetime(2022, 5, 28, 13, 13, 33, tzinfo=datetime.timezone.utc), b'Obat puyeng orang Sunda tidak hanya apotik hidup atau apotik pinggir jalan tapi bisa juga SEBLAK https://t.co/OXmg2GihH7', 564450110, None]\n",
            "[datetime.datetime(2022, 5, 28, 12, 39, 48, tzinfo=datetime.timezone.utc), b'semenjak asam lambung naik berunjung dirawat, ga bisa bangun samsek skrg beneran gabisa makan seblak bgt, nyoba mak\\xe2\\x80\\xa6 https://t.co/6MCT5i9ey6', 1279398500, None]\n",
            "[datetime.datetime(2022, 5, 28, 8, 36, 23, tzinfo=datetime.timezone.utc), b'@mirtaellaa10 mie toping seblak', 1467738368918228993, None]\n",
            "[datetime.datetime(2022, 5, 28, 2, 42, 2, tzinfo=datetime.timezone.utc), b'pagi pagi uda kepengen seblak', 1151674077418885120, None]\n"
          ]
        }
      ],
      "source": [
        "# Mari kita coba #3 gunakan google (map) untuk koordinat suatu lokasi\n",
        "# http://thoughtfaucet.com/search-twitter-by-location/\n",
        "# misal search tweet tentang \"makanan\" di Depok dan sekitarnya\n",
        "radius = '10km'\n",
        "Geo = ','.join([lat, lon, radius])\n",
        "qry = 'seblak'\n",
        "for tweet_ in tweepy.Cursor(api.search_tweets, q=qry, geocode=Geo).items(N):\n",
        "    print([tweet_.created_at, tweet_.text.encode('utf-8'), tweet_.user.id, tweet_.geo])"
      ],
      "id": "52dd3506"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b36b389d"
      },
      "outputs": [],
      "source": [
        "# Streaming tweets. Untuk percobaan pilih topicS sesuatu yg sedang trending/populer \"saat ini\".\n",
        "# Atau bisa coba dengan mengirim tweet sendiri :)\n",
        "from twython import TwythonStreamer\n",
        "\n",
        "def streamTwitter(topicS, lang):\n",
        "    class MyStreamer(TwythonStreamer):\n",
        "        def on_success(self, data):\n",
        "            global count\n",
        "            count+=1\n",
        "            print('tweet from {}, post: {}'.format(data['user']['screen_name'], data['text']))\n",
        "            if count==maxTweet:\n",
        "                print('\\nFinished streaming %.0f tweets' %(maxTweet)); self.disconnect()\n",
        "        def on_error(self, status_code, data):\n",
        "            print('Error Status = %s' %status_code); self.disconnect()\n",
        "\n",
        "    while count<maxTweet:\n",
        "        stream = MyStreamer(Ck, Cs, At, As)\n",
        "        stream.statuses.filter(track=topicS)"
      ],
      "id": "b36b389d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0e1b234f",
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a31d650f-8333-45e4-8f04-d602702009f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tweet from ByunnBaekhyun23, post: RT @NCT139FESS: Arkana sayang bgt ma a eril ,foto a eril di dicium trs😭😭😭\n",
            "\n",
            "Lihat video ini nangis bgt Al Fatihah buat a eril 🙏🏻 https://t.c…\n",
            "tweet from GeorginaZaskia, post: RT @nickspegal9yaho: Rest in love \n",
            "Tiba dirumah dinas gubernur jawa Barat ridwan kamil langsung disambut arkana adik angkat nya eril  , sed…\n",
            "tweet from lailiya25829261, post: RT @DawnOfMancs: Jepretan tadi siang, Adek Arkana lagi liat foto Aa Eril yg Gagah. Sedih bgt tapi kita harus ikhlas.\n",
            "\n",
            "Pamit pulang ke JKT y…\n",
            "tweet from lestariology, post: RT @AREAJULID: Dis! Nyesek banget liat ini, anak sekecil Arka pasti belum ngerti kalo kakaknya udah men1nggal😭😭\n",
            "\n",
            "Rest in love, Eril. Al fat…\n",
            "tweet from like_limelightt, post: RT @AREAJULID: Dis! Nyesek banget liat ini, anak sekecil Arka pasti belum ngerti kalo kakaknya udah men1nggal😭😭\n",
            "\n",
            "Rest in love, Eril. Al fat…\n",
            "\n",
            "Finished streaming 5 tweets\n"
          ]
        }
      ],
      "source": [
        "maxTweet, count = 5, 0 # Rubah sesuai dengan kebutuhan, Untuk percobaan ini cukup (misal) 12 tweet\n",
        "lan = set(['en','id']) # bahasa bisa dipilih > 1\n",
        "topicS = ['eril', 'ridwan kamil'] # Bisa>1\n",
        "\n",
        "streamTwitter(topicS, lan)"
      ],
      "id": "0e1b234f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "275ca5f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51b8cec8-68bd-4a94-9721-433feba34973"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['diketahuinya', 'menuturkan', 'seolah-olah', 'diakhirinya', 'kalaupun']"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# preprocess \"D\": kumpulan tweet\n",
        "slangFixId = tau.loadCorpus(file = 'data/slang.txt', sep=':')\n",
        "stopId, _ = tau.LoadStopWords(lang='id')\n",
        "stopId.add(\"rt\")\n",
        "\n",
        "list(stopId)[:5]"
      ],
      "id": "275ca5f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ee47cb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "3392fd9a-bd85-4e60-d3c4-4f15a9928c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:00<00:00, 1719.43it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Done'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "cleanD = []\n",
        "for t in tqdm(D):\n",
        "    doc = tau.cleanText(t, fix=slangFixId, lan='id', stops = stopId)\n",
        "    cleanD.append(doc)\n",
        "\n",
        "\"Done\""
      ],
      "id": "ee47cb8c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ad1a1fc7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "043ab233-3ed4-4f7c-b40e-2ab6d8c22c25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RT @SmashNewsCorp: Smash News - Industri plat merah belum menjual bahan bakar minyak( BBM) non- subsidi yang cocok dengan harga keekonomian…\n",
            "\n",
            "smashnewscorp smash news industri plat merah menjual bahan bakar minyak bbm non subsidi cocok harga keekonomian\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(D[0], end='\\n\\n')\n",
        "print(cleanD[0], end='\\n\\n')"
      ],
      "id": "ad1a1fc7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8a957b3c"
      },
      "outputs": [],
      "source": [
        "# Save ke txt ... lalu nanti akan di upload ke Voyant Tools\n",
        "filename = 'tweets_2021.txt'\n",
        "with open(filename, 'w') as f:\n",
        "    for T in cleanD:\n",
        "        f.write(T+'\\n')\n",
        "\n",
        "\"Tweets Saved!\""
      ],
      "id": "8a957b3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97ddb6ac"
      },
      "source": [
        "# <center><font color=\"blue\">HashTag Analysis</font></center>\n",
        "\n",
        "* Frequency-Based\n",
        "* Bisa ditambahkan analisa hashtags analysis ini dari waktu ke waktu"
      ],
      "id": "97ddb6ac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "980b0ce9"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "HTfilters = set(['zz', 'architec', 'prize', 'stirli', 'architect', 'london', 'cpd', 'design', 'stirling', 'photogr', 'gemini',\n",
        "                 'mule', 'karaoke', 'playing', 'official', 'berita', 'follow', 'retweet', 'mufc', 'ntms', 'infolimit', 'eeaa',\n",
        "                 'eaa', 'cfc', 'caprico', 'breaking','news', 'libra', 'mereka', 'brankas', 'psikolog', 'aquarius', 'klc'])\n",
        "# modifikasi HTfilters sesuai data kamu\n",
        "HT = {'hashtags':[]}\n",
        "count = 0\n",
        "getHashTags = re.compile(r\"#(\\w+)\")\n",
        "for i, d in tqdm(enumerate(D)):\n",
        "    hashtags = re.findall(getHashTags, d)\n",
        "    if hashtags:\n",
        "        TG = []\n",
        "        for tag in hashtags:\n",
        "            dTag = str(tag).strip().lower()\n",
        "            if len(dTag)>2:\n",
        "                add = True\n",
        "                for f in HTfilters:\n",
        "                    if f in dTag:\n",
        "                        add=False; break\n",
        "                if add:\n",
        "                    TG.append('#'+dTag); count += 1\n",
        "            HT['hashtags'].append(TG)\n",
        "print('Found {} number of hashtags'.format(count))"
      ],
      "id": "980b0ce9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "734d0b24"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "N = 50 # Number of top frequent hashtags to be plotted\n",
        "\n",
        "dtHT = [x for t in tqdm(HT['hashtags']) for x in t] # any(h not in x for h in HTfilters)\n",
        "dtHT = pd.Series(dtHT)\n",
        "dtHT = dtHT.value_counts()\n",
        "dtHT = dtHT.sort_index()\n",
        "dtHT = dtHT.sort_values(ascending = False)\n",
        "dtHT.to_csv('hashTags_2021.csv', encoding='utf8')\n",
        "dtHT = dtHT.iloc[:N]\n",
        "\n",
        "p = dtHT.plot(kind='barh', figsize=(12,8), legend = False)"
      ],
      "id": "734d0b24"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc193ce1"
      },
      "source": [
        "# Web Scrapping?"
      ],
      "id": "fc193ce1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d898ecae",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "import urllib.request\n",
        "from bs4 import BeautifulSoup as bs\n",
        "\n",
        "URL = 'https://www.beritasatu.com/beritasatu-tv'\n",
        "Doc = urllib.request.urlopen(URL).read()\n",
        "Doc = bs(Doc,'lxml').text\n",
        "print(Doc)"
      ],
      "id": "d898ecae"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06f01a28"
      },
      "source": [
        "# Loading Local Documents\n",
        "\n",
        "1. Instalasi Java\n",
        " - JDK 8 ... ingat harus JDK 8\n",
        " - https://www.oracle.com/id/java/technologies/javase/javase-jdk8-downloads.html\n",
        " - Set Java Home Directory\n",
        "2. Instalasi Tika Server :\n",
        " - Download Tika App Executable Java Jar: https://archive.apache.org/dist/tika/tika-app-1.24.1.jar\n",
        " - Put in Python home directory\n",
        "3. Instalasi Module Python Tika\n",
        "4. Reading pdf Files (Python Code below)\n",
        "\n",
        "### Tika can read Pdf, DocX, PPTX, etc."
      ],
      "id": "06f01a28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "28d4b8ef"
      },
      "outputs": [],
      "source": [
        "from tika import parser#, unpack\n",
        "\n",
        "def readDocs(file):\n",
        "    if 'pdf' in file:\n",
        "        headers = {'X-Tika-PDFextractInlineImages': 'true',}\n",
        "        raw = parser.from_file(file, headers=headers)\n",
        "    else:\n",
        "        raw = parser.from_file(file)\n",
        "    if 'content' in raw.keys():\n",
        "        return raw['content']\n",
        "    else:\n",
        "        return None"
      ],
      "id": "28d4b8ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "caea787e",
        "scrolled": false
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    doc = readDocs('data/contoh.pdf')\n",
        "except:\n",
        "    !mkdir data\n",
        "    !wget -P data/ https://raw.githubusercontent.com/taudata-indonesia/eLearning/master/data/contoh.pdf\n",
        "    doc = readDocs('data/contoh.pdf')\n",
        "\n",
        "print(doc)"
      ],
      "id": "caea787e"
    }
  ],
  "metadata": {
    "celltoolbar": "Slideshow",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "latex_envs": {
      "LaTeX_envs_menu_present": true,
      "autoclose": false,
      "autocomplete": true,
      "bibliofile": "biblio.bib",
      "cite_by": "apalike",
      "current_citInitial": 1,
      "eqLabelWithNumbers": true,
      "eqNumInitial": 1,
      "hotkeys": {
        "equation": "Ctrl-E",
        "itemize": "Ctrl-I"
      },
      "labels_anchors": false,
      "latex_user_defs": false,
      "report_style_numbering": false,
      "user_envs_cfg": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}